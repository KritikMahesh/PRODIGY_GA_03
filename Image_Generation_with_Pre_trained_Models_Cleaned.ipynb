{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088fae26",
   "metadata": {},
   "source": [
    "\n",
    "# üñºÔ∏è Project: Image Generation with Pre-trained Models (Stable Diffusion)\n",
    "\n",
    "**Name:** Kritik Mahesh  \n",
    "**Institution:** Manipal Academy of Higher Education, Dubai  \n",
    "**Platform:** Python (Jupyter Notebook / Google Colab)  \n",
    "**Libraries Used:**  \n",
    "- PyTorch  \n",
    "- Diffusers (Hugging Face)  \n",
    "- Matplotlib  \n",
    "- JSON & datetime utilities  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Project Objective  \n",
    "Utilize **pre-trained generative models** such as **Stable Diffusion** to create images from natural language prompts.  \n",
    "Explore the model‚Äôs ability to generate creative, high-quality, and contextually relevant images.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ What's Inside  \n",
    "- Install and load the **Stable Diffusion Pipeline** from Hugging Face Diffusers  \n",
    "- Prepare and customize **text prompts** for generation  \n",
    "- Generate multiple images from a single prompt  \n",
    "- Visualize results using **Matplotlib**  \n",
    "- Save generated images with timestamps for record-keeping\n",
    "\n",
    "---\n",
    "\n",
    "## üõ† Techniques Used  \n",
    "- **Pre-trained diffusion models** for text-to-image synthesis  \n",
    "- Hugging Face **Diffusers** API  \n",
    "- **Prompt engineering** to influence output quality and style  \n",
    "- Image visualization with **Matplotlib**  \n",
    "- File management & logging for generated outputs  \n",
    "\n",
    "---\n",
    "\n",
    "## üìÇ Features\n",
    "- Generate images from **custom prompts**.\n",
    "- Easily **customize generation parameters** such as guidance scale and inference steps.\n",
    "- Automatically **save generated images** with unique filenames.\n",
    "- Simple **visualization** of outputs inside the notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Tech Stack\n",
    "- **Python** (Google Colab / Jupyter Notebook)\n",
    "- **PyTorch**\n",
    "- **Diffusers** (Hugging Face)\n",
    "- **Matplotlib**\n",
    "- **JSON** & **datetime** for logging\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Requirements\n",
    "Install dependencies directly in your Colab or local environment:\n",
    "```bash\n",
    "pip install diffusers transformers accelerate torch matplotlib\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ How to Use\n",
    "1. **Clone or download the project files**:\n",
    "   ```bash\n",
    "   git clone https://github.com/yourusername/image-generation-stable-diffusion.git\n",
    "   cd image-generation-stable-diffusion\n",
    "   ```\n",
    "2. **Open the notebook** in Google Colab or Jupyter.  \n",
    "3. **Run all setup cells** to:\n",
    "   - Install dependencies\n",
    "   - Load the pre-trained **Stable Diffusion** model\n",
    "4. **Enter your text prompt** in the provided cell.\n",
    "5. **Generate images** and view them directly in the notebook.\n",
    "6. **Save outputs** ‚Äî images are automatically saved with timestamps for easy tracking.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Example\n",
    "**Prompt:**\n",
    "```\n",
    "A futuristic cityscape at sunset, digital art\n",
    "```\n",
    "**Generated Output:**  \n",
    "*(Example image will be shown here)*\n",
    "\n",
    "---\n",
    "\n",
    "## üìÑ License\n",
    "This project is open-source and available under the **MIT License**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159a7121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Image Generation with Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "Automatically generated by Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98282c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1vlg40QZpaE3G_e4pVuMFewqLlx9eRiWD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc4251c",
   "metadata": {},
   "source": [
    "# üñºÔ∏è Project: Image Generation with Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83662ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Platform:** Python (Jupyter Notebook / Google Colab)  \n",
    "**Libraries Used:**  \n",
    "- PyTorch  \n",
    "- Diffusers (Hugging Face)  \n",
    "- Matplotlib  \n",
    "- JSON & datetime utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb3171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9633c0",
   "metadata": {},
   "source": [
    "## üéØ Project Objective  \n",
    "Utilize **pre-trained generative models** such as **Stable Diffusion** to create images from natural language prompts.  \n",
    "Explore the model‚Äôs ability to generate creative, high-quality, and contextually relevant images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a8ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff9603e",
   "metadata": {},
   "source": [
    "## üì¶ What's Inside  \n",
    "- Install and load the **Stable Diffusion Pipeline** from Hugging Face Diffusers  \n",
    "- Prepare and customize **text prompts** for generation  \n",
    "- Generate multiple images from a single prompt  \n",
    "- Visualize results using **Matplotlib**  \n",
    "- Save generated images with timestamps for record-keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d872c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08735ce6",
   "metadata": {},
   "source": [
    "## üõ† Techniques Used  \n",
    "- **Pre-trained diffusion models** for text-to-image synthesis  \n",
    "- Hugging Face **Diffusers** API  \n",
    "- **Prompt engineering** to influence output quality and style  \n",
    "- Image visualization with **Matplotlib**  \n",
    "- File management & logging for generated outputs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e22cc",
   "metadata": {},
   "source": [
    "#@title üì¶ Install Packages\n",
    "#@markdown Run this first! Takes about 1-2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fea6683",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üé® Setting up AI image generation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45bb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = [\n",
    "    \"diffusers\",\n",
    "    \"transformers\",\n",
    "    \"accelerate\",\n",
    "    \"torch\",\n",
    "    \"matplotlib\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ef9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for package in packages:\n",
    "    print(f\"Installing {package}...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cf0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÖ All done! Continue to next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede7a6f0",
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12c1c7d",
   "metadata": {},
   "source": [
    "# Check if we have GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d14119",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÖ Ready to generate images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaf369d",
   "metadata": {},
   "source": [
    "# Load the AI model\n",
    "print(\"ü§ñ Loading Stable Diffusion model...\")\n",
    "print(\"(This takes 1-2 minutes first time)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912593de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a006154",
   "metadata": {},
   "source": [
    "# Make it faster\n",
    "if device == \"cuda\":\n",
    "    pipe.enable_attention_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f73e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÖ Model loaded! Ready to create images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c8735",
   "metadata": {},
   "source": [
    "# Keep track of our generations\n",
    "generation_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df8fb1e",
   "metadata": {},
   "source": [
    "#@title üé® Generate Image\n",
    "#@markdown Type your prompt and hit run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1697354",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A cute dog\" #@param {type:\"string\"}\n",
    "steps = 10 #@param {type:\"slider\", min:10, max:50, step:5}\n",
    "guidance = 1 #@param {type:\"slider\", min:1, max:15, step:0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86fd4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Creating: '{prompt}'\")\n",
    "print(f\" Steps: {steps}, Guidance: {guidance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15538b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eedbbaa",
   "metadata": {},
   "source": [
    "# Generate the image\n",
    "with torch.autocast(device):\n",
    "    result = pipe(\n",
    "        prompt=prompt,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=guidance,\n",
    "        width=512,\n",
    "        height=512\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = result.images[0]\n",
    "generation_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ff5c40",
   "metadata": {},
   "source": [
    "# Save info\n",
    "generation_info = {\n",
    "    'prompt': prompt,\n",
    "    'time': generation_time,\n",
    "    'steps': steps,\n",
    "    'guidance': guidance,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "generation_history.append(generation_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28302566",
   "metadata": {},
   "source": [
    "# Show the image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(f\"Generated in {generation_time:.1f} seconds\\n'{prompt}'\", fontsize=12, pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e310f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"‚úÖ Done! Generated in {generation_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a314e70e",
   "metadata": {},
   "source": [
    "# Clean up GPU memory\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b2aed",
   "metadata": {},
   "source": [
    "#@title üîÑ Generate Multiple Images\n",
    "#@markdown First choose how many prompts, then fill them in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d67c598",
   "metadata": {},
   "source": [
    "# Step 1: User chooses how many prompts\n",
    "num_prompts = 3 #@param {type:\"slider\", min:1, max:5, step:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aded7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üìù Please fill in {num_prompts} prompts below:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f447f0",
   "metadata": {},
   "source": [
    "# Step 2: Empty prompt boxes (user fills these)\n",
    "prompt1 = \"lil dog \" #@param {type:\"string\"}\n",
    "prompt2 = \"A NYC CITY\" #@param {type:\"string\"}\n",
    "prompt3 = \"A golden sky farm with animals \" #@param {type:\"string\"}\n",
    "prompt4 = \"\" #@param {type:\"string\"}\n",
    "prompt5 = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08d444",
   "metadata": {},
   "source": [
    "# Collect only the prompts the user wants\n",
    "all_prompts = [prompt1, prompt2, prompt3, prompt4, prompt5]\n",
    "prompts = [p.strip() for p in all_prompts[:num_prompts] if p.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feceb1f5",
   "metadata": {},
   "source": [
    "# Check if user filled in the prompts\n",
    "if len(prompts) == 0:\n",
    "    print(\"‚ùå Please fill in at least one prompt above and run again!\")\n",
    "elif len(prompts) < num_prompts:\n",
    "    print(f\"‚ö†Ô∏è  You selected {num_prompts} prompts but only filled {len(prompts)}. Using {len(prompts)} prompts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(prompts) > 0:\n",
    "    print(f\"\\nüîÑ Generating {len(prompts)} images...\")\n",
    "    print(\"üìù Your prompts:\")\n",
    "    for i, p in enumerate(prompts, 1):\n",
    "        print(f\"  {i}. {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "    times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83691f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, prompt in enumerate(prompts):\n",
    "        print(f\"\\nüé® {i+1}/{len(prompts)}: Generating '{prompt[:30]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf568bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17975db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autocast(device):\n",
    "            result = pipe(\n",
    "                prompt=prompt,\n",
    "                num_inference_steps=25,\n",
    "                guidance_scale=7.5\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = result.images[0]\n",
    "        gen_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c04a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.append(image)\n",
    "        times.append(gen_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588ccd9",
   "metadata": {},
   "source": [
    "# Save to history\n",
    "        generation_history.append({\n",
    "            'prompt': prompt,\n",
    "            'time': gen_time,\n",
    "            'steps': 25,\n",
    "            'guidance': 7.5,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604aacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"‚úÖ Done in {gen_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9c2da",
   "metadata": {},
   "source": [
    "# Show all images\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(5*len(images), 5))\n",
    "    if len(images) == 1:\n",
    "        axes = [axes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (image, prompt, time_taken) in enumerate(zip(images, prompts, times)):\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f\"Prompt {i+1}\\n{prompt[:25]}...\\n({time_taken:.1f}s)\", fontsize=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77cd70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüéâ All done! Average time: {sum(times)/len(times):.1f}s\")\n",
    "    print(f\"üìä Generated {len(images)} images in {sum(times):.1f} total seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552be86",
   "metadata": {},
   "source": [
    "#@title üé≠ Try Different Styles\n",
    "#@markdown Same prompt, different artistic styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495babae",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"a cute lil cat\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fedf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = [\n",
    "    \"oil painting\",\n",
    "    \"watercolor\",\n",
    "    \"digital art\",\n",
    "    \"cartoon style\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ef912",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üé≠ Trying different styles for: '{base_prompt}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_images = []\n",
    "style_times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575fc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for style in styles:\n",
    "    full_prompt = f\"{base_prompt}, {style}\"\n",
    "    print(f\"\\nGenerating: {style}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a750d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autocast(device):\n",
    "        result = pipe(\n",
    "            prompt=full_prompt,\n",
    "            num_inference_steps=30,\n",
    "            guidance_scale=8.0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16eac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = result.images[0]\n",
    "    gen_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_images.append(image)\n",
    "    style_times.append(gen_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6530081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_history.append({\n",
    "        'prompt': full_prompt,\n",
    "        'time': gen_time,\n",
    "        'steps': 30,\n",
    "        'guidance': 8.0,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"‚úÖ {gen_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9997164",
   "metadata": {},
   "source": [
    "# Show style comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "axes = axes.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58560ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (image, style, time_taken) in enumerate(zip(style_images, styles, style_times)):\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f\"{style.title()}\\n({time_taken:.1f}s)\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle(f\"Style Comparison: '{base_prompt}'\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüé® Style test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d306f2",
   "metadata": {},
   "source": [
    "#@title üìä Show some basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generation_history:\n",
    "    print(\"SESSION STATS\")\n",
    "    print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d1e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images = len(generation_history)\n",
    "    times = [g['time'] for g in generation_history]\n",
    "    avg_time = sum(times) / len(times)\n",
    "    fastest = min(times)\n",
    "    slowest = max(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4250b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Images generated: {total_images}\")\n",
    "    print(f\" Average time: {avg_time:.1f}s\")\n",
    "    print(f\" Fastest: {fastest:.1f}s\")\n",
    "    print(f\" Slowest: {slowest:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8afb1b",
   "metadata": {},
   "source": [
    "# Simple chart\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(range(len(times)), times, color='skyblue')\n",
    "    plt.xlabel('Image Number')\n",
    "    plt.ylabel('Generation Time (seconds)')\n",
    "    plt.title('Generation Times')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No images generated yet! Try the cells above first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544d846",
   "metadata": {},
   "source": [
    "#@title üíæ Save Results\n",
    "#@markdown Save your session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051fcd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generation_history:\n",
    "    # Create simple report\n",
    "    report = {\n",
    "        \"project\": \"AI Image Generation Internship\",\n",
    "        \"date\": datetime.now().isoformat(),\n",
    "        \"total_images\": len(generation_history),\n",
    "        \"average_time\": sum(g['time'] for g in generation_history) / len(generation_history),\n",
    "        \"generations\": generation_history\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49896e14",
   "metadata": {},
   "source": [
    "# Save as JSON\n",
    "    filename = f\"image_generation_results_{datetime.now().strftime('%Y%m%d_%H%M')}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa88760",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'w') as f:\n",
    "        json.dump(report, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üíæ Results saved to: {filename}\")\n",
    "    print(f\"üìä Generated {report['total_images']} images\")\n",
    "    print(f\"‚è±Ô∏è  Average time: {report['average_time']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60484ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ Perfect for your internship presentation!\")\n",
    "else:\n",
    "    print(\"Nothing to save yet! Generate some images first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ac876",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd412ab0",
   "metadata": {},
   "source": [
    "## END\n",
    "## ^ . ^ /\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
