{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üé® Image Generation with Stable Diffusion\n",
        "## Internship Project - AI Image Generation\n",
        "\n",
        "**What this does:**\n",
        "- ü§ñ Generate images from text prompts\n",
        "- üé≠ Try different artistic styles\n",
        "- üìä Track generation time and quality\n",
        "- üíæ Save results\n",
        "\n",
        "**Based on:** Stable Diffusion tutorial but with some cool extras!\n",
        "\n",
        "---\n",
        "**Author:** [Your Name]  \n",
        "**Date:** 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# Install Packages\n",
        "# Run this first! Takes about 1-2 minutes\n",
        "\n",
        "print(\"üé® Setting up AI image generation...\")\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = [\n",
        "    \"diffusers\",\n",
        "    \"transformers\", \n",
        "    \"accelerate\",\n",
        "    \"torch\",\n",
        "    \"matplotlib\"\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    print(f\"Installing {package}...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])\n",
        "\n",
        "print(\"‚úÖ All done! Continue to next cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# Check if we have GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using: {device}\")\n",
        "if device == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "print(\"‚úÖ Ready to generate images!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_model"
      },
      "outputs": [],
      "source": [
        "# Load the AI model\n",
        "print(\"ü§ñ Loading Stable Diffusion model...\")\n",
        "print(\"(This takes 1-2 minutes first time)\")\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "    safety_checker=None,\n",
        "    requires_safety_checker=False\n",
        ").to(device)\n",
        "\n",
        "# Make it faster\n",
        "if device == \"cuda\":\n",
        "    pipe.enable_attention_slicing()\n",
        "\n",
        "print(\"‚úÖ Model loaded! Ready to create images!\")\n",
        "\n",
        "# Keep track of our generations\n",
        "generation_history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_image"
      },
      "outputs": [],
      "source": [
        "# Generate Single Image\n",
        "# Change these variables to customize:\n",
        "\n",
        "prompt = \"A cute robot painting a picture in an art studio\"\n",
        "steps = 15  # 10-50, lower = faster\n",
        "guidance = 7.5  # 1-15, higher = follows prompt more\n",
        "\n",
        "print(f\"üé® Creating: '{prompt}'\")\n",
        "print(f\"‚öôÔ∏è Steps: {steps}, Guidance: {guidance}\")\n",
        "\n",
        "start_time = time.time()\n",
        "print(\"üîÑ Generating... (this takes 10-30 seconds)\")\n",
        "\n",
        "# Generate the image\n",
        "with torch.autocast(device):\n",
        "    result = pipe(\n",
        "        prompt=prompt,\n",
        "        num_inference_steps=steps,\n",
        "        guidance_scale=guidance,\n",
        "        width=512,\n",
        "        height=512\n",
        "    )\n",
        "\n",
        "image = result.images[0]\n",
        "generation_time = time.time() - start_time\n",
        "\n",
        "# Save info\n",
        "generation_info = {\n",
        "    'prompt': prompt,\n",
        "    'time': generation_time,\n",
        "    'steps': steps,\n",
        "    'guidance': guidance,\n",
        "    'timestamp': datetime.now().isoformat()\n",
        "}\n",
        "generation_history.append(generation_info)\n",
        "\n",
        "# Show the image\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Generated in {generation_time:.1f} seconds\\n'{prompt}'\", fontsize=12, pad=20)\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úÖ Done! Generated in {generation_time:.1f} seconds\")\n",
        "\n",
        "# Clean up GPU memory\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batch_generate"
      },
      "outputs": [],
      "source": [
        "# Generate Multiple Images\n",
        "# Edit the prompts list below:\n",
        "\n",
        "prompts = [\n",
        "    \"A magical forest with glowing mushrooms\",\n",
        "    \"A futuristic city at sunset\", \n",
        "    \"A cozy coffee shop in winter\"\n",
        "]\n",
        "\n",
        "print(f\"üîÑ Generating {len(prompts)} images...\")\n",
        "\n",
        "images = []\n",
        "times = []\n",
        "\n",
        "for i, prompt in enumerate(prompts):\n",
        "    print(f\"\\n{i+1}/{len(prompts)}: {prompt}\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    with torch.autocast(device):\n",
        "        result = pipe(\n",
        "            prompt=prompt,\n",
        "            num_inference_steps=25,\n",
        "            guidance_scale=7.5\n",
        "        )\n",
        "    \n",
        "    image = result.images[0]\n",
        "    gen_time = time.time() - start_time\n",
        "    \n",
        "    images.append(image)\n",
        "    times.append(gen_time)\n",
        "    \n",
        "    generation_history.append({\n",
        "        'prompt': prompt,\n",
        "        'time': gen_time,\n",
        "        'steps': 25,\n",
        "        'guidance': 7.5,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    })\n",
        "    \n",
        "    print(f\"‚úÖ Done in {gen_time:.1f}s\")\n",
        "\n",
        "# Show all images\n",
        "fig, axes = plt.subplots(1, len(images), figsize=(5*len(images), 5))\n",
        "if len(images) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, (image, prompt, time_taken) in enumerate(zip(images, prompts, times)):\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].axis('off')\n",
        "    axes[i].set_title(f\"{prompt}\\n({time_taken:.1f}s)\", fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüéâ All done! Average time: {sum(times)/len(times):.1f}s\")\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "style_test"
      },
      "outputs": [],
      "source": [
        "# Try Different Styles\n",
        "# Change the base_prompt below:\n",
        "\n",
        "base_prompt = \"A mountain landscape\"\n",
        "\n",
        "styles = [\n",
        "    \"oil painting\",\n",
        "    \"watercolor\",\n",
        "    \"digital art\",\n",
        "    \"cartoon style\"\n",
        "]\n",
        "\n",
        "print(f\"üé≠ Trying different styles for: '{base_prompt}'\")\n",
        "\n",
        "style_images = []\n",
        "style_times = []\n",
        "\n",
        "for style in styles:\n",
        "    full_prompt = f\"{base_prompt}, {style}\"\n",
        "    print(f\"\\nGenerating: {style}\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    with torch.autocast(device):\n",
        "        result = pipe(\n",
        "            prompt=full_prompt,\n",
        "            num_inference_steps=30,\n",
        "            guidance_scale=8.0\n",
        "        )\n",
        "    \n",
        "    image = result.images[0]\n",
        "    gen_time = time.time() - start_time\n",
        "    \n",
        "    style_images.append(image)\n",
        "    style_times.append(gen_time)\n",
        "    \n",
        "    generation_history.append({\n",
        "        'prompt': full_prompt,\n",
        "        'time': gen_time,\n",
        "        'steps': 30,\n",
        "        'guidance': 8.0,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    })\n",
        "    \n",
        "    print(f\"‚úÖ {gen_time:.1f}s\")\n",
        "\n",
        "# Show style comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (image, style, time_taken) in enumerate(zip(style_images, styles, style_times)):\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].axis('off')\n",
        "    axes[i].set_title(f\"{style.title()}\\n({time_taken:.1f}s)\", fontsize=12)\n",
        "\n",
        "plt.suptitle(f\"Style Comparison: '{base_prompt}'\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüé® Style test complete!\")\n",
        "\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stats"
      },
      "outputs": [],
      "source": [
        "# Show Session Stats\n",
        "if generation_history:\n",
        "    print(\"üìä SESSION STATS\")\n",
        "    print(\"=\" * 20)\n",
        "    \n",
        "    total_images = len(generation_history)\n",
        "    times = [g['time'] for g in generation_history]\n",
        "    avg_time = sum(times) / len(times)\n",
        "    fastest = min(times)\n",
        "    slowest = max(times)\n",
        "    \n",
        "    print(f\"üñºÔ∏è  Images generated: {total_images}\")\n",
        "    print(f\"‚è±Ô∏è  Average time: {avg_time:.1f}s\")\n",
        "    print(f\"üöÄ Fastest: {fastest:.1f}s\")\n",
        "    print(f\"üêå Slowest: {slowest:.1f}s\")\n",
        "    \n",
        "    # Simple chart\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.bar(range(len(times)), times, color='skyblue')\n",
        "    plt.xlabel('Image Number')\n",
        "    plt.ylabel('Generation Time (seconds)')\n",
        "    plt.title('Generation Times')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n‚úÖ Not bad for an internship project! üéâ\")\n",
        "else:\n",
        "    print(\"No images generated yet! Try the cells above first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_results"
      },
      "outputs": [],
      "source": [
        "# Save Results\n",
        "if generation_history:\n",
        "    # Create simple report\n",
        "    report = {\n",
        "        \"project\": \"AI Image Generation Internship\",\n",
        "        \"date\": datetime.now().isoformat(),\n",
        "        \"total_images\": len(generation_history),\n",
        "        \"average_time\": sum(g['time'] for g in generation_history) / len(generation_history),\n",
        "        \"generations\": generation_history\n",
        "    }\n",
        "    \n",
        "    # Save as JSON\n",
        "    filename = f\"image_generation_results_{datetime.now().strftime('%Y%m%d_%H%M')}.json\"\n",
        "    \n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "    \n",
        "    print(f\"üíæ Results saved to: {filename}\")\n",
        "    print(f\"üìä Generated {report['total_images']} images\")\n",
        "    print(f\"‚è±Ô∏è  Average time: {report['average_time']:.1f}s\")\n",
        "    \n",
        "    print(\"\\nüéØ Perfect for your internship presentation!\")\n",
        "else:\n",
        "    print(\"Nothing to save yet! Generate some images first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "# üéâ Project Complete!\n",
        "\n",
        "## What You Built:\n",
        "‚úÖ **AI Image Generator** using Stable Diffusion  \n",
        "‚úÖ **Interactive controls** with sliders and text inputs  \n",
        "‚úÖ **Batch processing** for multiple images  \n",
        "‚úÖ **Style comparison** testing different artistic styles  \n",
        "‚úÖ **Performance tracking** with generation times  \n",
        "‚úÖ **Data export** for presentation  \n",
        "\n",
        "## Why This Is Good for Internship:\n",
        "- ü§ñ Shows you understand **AI/ML concepts**\n",
        "- üíª Demonstrates **coding skills** in Python\n",
        "- üìä Includes **data analysis** and visualization\n",
        "- üé® Has **creative applications**\n",
        "- üì± **Interactive and user-friendly**\n",
        "\n",
        "## Next Steps:\n",
        "1. **Download** this notebook\n",
        "2. **Run it** and generate some cool images\n",
        "3. **Save** your results\n",
        "4. **Show** it in your internship interview!\n",
        "\n",
        "**Good luck! üöÄ**"
      ]
    }
  ]
}
